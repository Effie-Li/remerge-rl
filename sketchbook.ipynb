{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_minigrid.wrappers import *\n",
    "from env import *\n",
    "from memory import ReplayBuffer, RemergeMemory\n",
    "from agent import DQN\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "\n",
    "device = torch.device(\"cuda:4\")\n",
    "\n",
    "class RandomAgent:\n",
    "    def __init__(self, action_dim):\n",
    "        self.action_dim = action_dim\n",
    "    \n",
    "    def step(self, observation=None):\n",
    "        return np.random.randint(self.action_dim)\n",
    "\n",
    "# [1,2,\n",
    "#  3,4]\n",
    "# 0-up, 1-right, 2-down, 3-left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agent related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = FourRoomsTask(task_type='fixed', \n",
    "                     agent_ini_pos=(2,2),\n",
    "                     goal_pos=(2,4),\n",
    "                     reward_type='sparse', \n",
    "                     goalcond=True, \n",
    "                     seed=32)\n",
    "obs = task.reset()\n",
    "memory = ReplayBuffer()\n",
    "agent = DQN(state_dim=obs['image'].shape, action_dim=4, goalcond=True, \n",
    "            device=device, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = FourRoomsTask(task_type='preset', \n",
    "                     agent_ini_pos=(12,12),\n",
    "                     goal_pos=(9,13),\n",
    "                     reward_type='sparse', \n",
    "                     goalcond=True, \n",
    "                     seed=32)\n",
    "# task.set_phase('test')\n",
    "obs = task.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task.clone()\n",
    "obs = task.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 False\n"
     ]
    }
   ],
   "source": [
    "# 0-left, 1-down, 2-right, 3-up\n",
    "obs, r, done, _ = task.step(2)\n",
    "print(r, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'goal')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(obs['image'][0])\n",
    "axes[1].imshow(obs['goal'][0])\n",
    "axes[0].set_title('start')\n",
    "axes[1].set_title('goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "        dtype=uint8),\n",
       "  'goal': array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "        dtype=uint8),\n",
       "  'mission': 'Reach the goal'},\n",
       " 0.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10168855323143527"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05 + (0.9 - 0.05) * \\\n",
    "    math.exp(-1. * 700 / 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*19*19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = memory.sample(batch_size=3)\n",
    "\n",
    "state_batch = torch.cat(batch.state)\n",
    "goal_batch = torch.cat(batch.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 361])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_batch.view(state_batch.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 722])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((state_batch.view(state_batch.size(0), -1), state_batch.view(goal_batch.size(0), -1)), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### memory related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = FourRoomsTask(task_type='ti-2', \n",
    "                     reward_type='sparse2', \n",
    "                     goalcond=True, \n",
    "                     seed=32)\n",
    "ra = RandomAgent(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = task.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'goal')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(obs['image'][0])\n",
    "axes[1].imshow(obs['goal'][0])\n",
    "axes[0].set_title('start')\n",
    "axes[1].set_title('goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayBuffer(num_slot=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect some random transitions for prototyping\n",
    "\n",
    "obs = task.reset()\n",
    "state = torch.from_numpy(obs['image'].astype(np.float32)).unsqueeze(0)\n",
    "goal = torch.from_numpy(obs['goal'].astype(np.float32)).unsqueeze(0)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    action = ra.step(state)\n",
    "    next_obs, reward, done, _ = task.step(action)\n",
    "    next_state = torch.from_numpy(next_obs['image'].astype(np.float32)).unsqueeze(0)\n",
    "    # goal shouldn't change within an episode\n",
    "    reward = torch.tensor([reward], dtype=torch.float)\n",
    "\n",
    "    if done:\n",
    "        next_state = None\n",
    "\n",
    "    memory.add(state, action, reward, next_state, goal)\n",
    "    if done:\n",
    "        obs = task.reset()\n",
    "        state = torch.from_numpy(obs['image'].astype(np.float32)).unsqueeze(0)\n",
    "        goal = torch.from_numpy(obs['goal'].astype(np.float32)).unsqueeze(0)\n",
    "    else:\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttractorNetwork:\n",
    "    \n",
    "    '''\n",
    "    instance-based memory with recurrent computations\n",
    "    onehot memory code can be used as key to another memory storage\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hidden_size, \n",
    "                 state_size,\n",
    "                 raw_excite_weight=1.0,\n",
    "                 raw_inhibit_weight=0.0,\n",
    "                 weight_scale=1.0,\n",
    "                 i_tau=0.1, \n",
    "                 h_tau=0.04, \n",
    "                 h_C=0., \n",
    "                 lmda=0.5, \n",
    "                 ext=0.2):\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.weight_scale = weight_scale # class hyperparam?\n",
    "        self.excite = raw_excite_weight * self.weight_scale\n",
    "        self.inhibit = raw_inhibit_weight * self.weight_scale\n",
    "        \n",
    "        self.i_tau = i_tau\n",
    "        self.h_tau = h_tau\n",
    "        self.h_C = h_C\n",
    "        self.lmda = lmda\n",
    "        self.ext = ext\n",
    "        \n",
    "        self.weights = {\n",
    "            's2h':np.zeros((self.state_size, self.hidden_size)),\n",
    "            'h2s':np.zeros((self.hidden_size, self.state_size)),\n",
    "            'ns2h':np.zeros((self.state_size, self.hidden_size)),\n",
    "            'h2ns':np.zeros((self.hidden_size, self.state_size)),\n",
    "        }\n",
    "        \n",
    "        self.netin_buffer = {\n",
    "            's':np.zeros((1, self.state_size)),\n",
    "            'ns':np.zeros((1, self.state_size)),\n",
    "            'h':np.zeros((1, self.hidden_size))\n",
    "        }\n",
    "    \n",
    "    def update_weights(self, weight_dict_key, pre_index, post_index, mode='add'):\n",
    "        # add or remove a specific weight between state and link\n",
    "        # pre_index indicates the node whose outgoing weights are being updated\n",
    "        # post_index indicates the node whose incoming weights are being updated\n",
    "        new_weights = self.weights[weight_dict_key][pre_index]\n",
    "\n",
    "        if mode == 'add':\n",
    "            new_weights[post_index] = self.excite\n",
    "            # update zero weights to inhibitory\n",
    "            new_weights[new_weights==0.0] = self.inhibit\n",
    "\n",
    "        elif mode == 'del':\n",
    "            new_weights[post_index] = inhibit\n",
    "            # if no more excitatory connections change all weights to zero\n",
    "            if sum(new_weights==excite) == 0:\n",
    "                new_weights = np.zeros(len(new_weights))\n",
    "\n",
    "        self.weights[weight_dict_key][pre_index] = new_weights\n",
    "\n",
    "    def i_activation(self, netin):\n",
    "        # logistic\n",
    "        # return np.array([1/(1+np.exp(-x/self.i_tau)) for x in netin])\n",
    "        # softmax\n",
    "        denom = np.sum([np.exp(x/self.i_tau) for x in netin])\n",
    "        return np.array([np.exp(x/self.i_tau)/denom for x in netin])\n",
    "\n",
    "    def h_activation(self, netin):\n",
    "        # hedge softmax\n",
    "        denom = self.h_C**(1/self.h_tau) + np.sum([np.exp(x/self.h_tau) for x in netin])\n",
    "        return np.array([np.exp(x/self.h_tau)/denom for x in netin])\n",
    "\n",
    "    def forward(self, s_in=None, ns_in=None):\n",
    "        \n",
    "        s_in = s_in if s_in is not None else np.zeros((1,self.state_size))\n",
    "        ns_in = ns_in if ns_in is not None else np.zeros((1,self.state_size))\n",
    "\n",
    "        snetin = np.dot(self.h_activation(self.netin_buffer['h']),self.weights['h2s']) + self.ext*s_in\n",
    "        snetin = self.lmda*(snetin) + (1-self.lmda)*self.netin_buffer['s']\n",
    "        nsnetin = np.dot(self.h_activation(self.netin_buffer['h']),self.weights['h2ns']) + self.ext*ns_in\n",
    "        nsnetin = self.lmda*(nsnetin) + (1-self.lmda)*self.netin_buffer['ns']\n",
    "        hnetin = np.dot(self.i_activation(snetin),self.weights['s2h']) + np.dot(self.i_activation(nsnetin),self.weights['ns2h'])\n",
    "        hnetin = self.lmda*(hnetin) + (1-self.lmda)*self.netin_buffer['h']\n",
    "\n",
    "        # update netin buffer\n",
    "        self.netin_buffer['s'] = snetin\n",
    "        self.netin_buffer['ns'] = nsnetin\n",
    "        self.netin_buffer['h'] = hnetin\n",
    "\n",
    "        # compute activation\n",
    "        sact = self.i_activation(snetin)\n",
    "        nsact = self.i_activation(nsnetin)\n",
    "        hact = self.h_activation(hnetin)\n",
    "\n",
    "        return sact, nsact, hact\n",
    "    \n",
    "    def clean_buffer(self):\n",
    "        self.netin_buffer = {\n",
    "            's':np.zeros((1, self.state_size)),\n",
    "            'ns':np.zeros((1, self.state_size)),\n",
    "            'h':np.zeros((1, self.hidden_size))\n",
    "        }\n",
    "    \n",
    "    def clone(self):\n",
    "        x = AttractorNetwork(hidden_size=self.hidden_size, \n",
    "                             state_size=self.state_size, \n",
    "                             weight_scale=self.weight_scale,\n",
    "                             i_tau=self.i_tau, \n",
    "                             h_tau=self.h_tau, \n",
    "                             h_C=self.h_C, \n",
    "                             lmda=self.lmda, \n",
    "                             ext=self.ext)\n",
    "        x.weights = self.weights.copy()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linked = namedtuple('Linked', ('state1', 'state2', 'step'))\n",
    "\n",
    "class RemergeMemory(ReplayBuffer):\n",
    "    \n",
    "    '''\n",
    "    wrapper for remerge, maintains memory content storages for state and hidden layers\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_slot=10000,\n",
    "                 batch_size=32,\n",
    "                 hidden_size=1000, \n",
    "                 state_size=1000,\n",
    "                 **kwargs):\n",
    "        \n",
    "        # self.memory is inherited from super, functions as the default batch sampling buffer\n",
    "        # self.remerge is the memory network that does recurrent computation on onehot memory keys\n",
    "        # self.states, next_states, and links are the corresponding content storage for self.remerge\n",
    "        \n",
    "        super().__init__(num_slot=num_slot, batch_size=batch_size)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        self.attractor_network = AttractorNetwork(hidden_size, state_size, **kwargs)\n",
    "        self.states = deque()\n",
    "        self.next_states = deque()\n",
    "        self.links = deque()\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, goal=None):\n",
    "        super().add(state, action, reward, next_state, goal=None)\n",
    "        \n",
    "        # the incoming states are [B, C, H, W] tensors\n",
    "        # convert to [C, H, W] np arrays\n",
    "        # TODO: but don't forget to convert back!\n",
    "        state = state.detach().numpy()[0]\n",
    "        next_state = next_state.detach().numpy()[0]\n",
    "        \n",
    "        step = 1 # new links are always 1-step transitions\n",
    "        new_link = Linked(*(state, next_state, step))\n",
    "\n",
    "        if self.find_link(self.links, new_link) != -1:\n",
    "            # memory link exists, don't need to adjust memory network weights\n",
    "            return\n",
    "\n",
    "        # TODO: maintain num_slots in all of (links, states, next_states)\n",
    "        # TODO: when memory is freed up need to update weights\n",
    "        \n",
    "        # assuming implementation is correct, effective length of\n",
    "        # states and next_states will always be <= links, so\n",
    "        # we only need to check link capacity and free things accordingly\n",
    "        if len(self.links) > self.hidden_size:\n",
    "            pass\n",
    "\n",
    "        self.links.append(new_link)\n",
    "        link_index = len(self.links)-1\n",
    "\n",
    "        state_index = self.find_state(self.states, state)\n",
    "        if state_index == -1:\n",
    "            self.states.append(state)\n",
    "            state_index = len(self.states)-1\n",
    "\n",
    "        next_state_index = self.find_state(self.next_states, next_state)\n",
    "        if next_state_index == -1:\n",
    "            self.next_states.append(next_state)\n",
    "            next_state_index = len(self.next_states)-1\n",
    "\n",
    "        # construct new weights as memory comes in\n",
    "        self.attractor_network.update_weights('s2h', pre_index=state_index, post_index=link_index, mode='add')\n",
    "        self.attractor_network.update_weights('h2s', pre_index=link_index, post_index=state_index, mode='add')\n",
    "        self.attractor_network.update_weights('ns2h', pre_index=next_state_index, post_index=link_index, mode='add')\n",
    "        self.attractor_network.update_weights('h2ns', pre_index=link_index, post_index=next_state_index, mode='add')\n",
    "    \n",
    "    def plan(self, s_probe=None, ns_probe=None, plan_steps=4, T=200, mode='max'):\n",
    "        \n",
    "        # plan_steps needs to be >=1\n",
    "        # probes are in memory content space (e.g. [C,H,W])\n",
    "        # ns_probe is goal state\n",
    "        # self.attractor_network.forward can take None inputs\n",
    "        # if plan_steps==0 one of s_probe and ns_probe better be None\n",
    "        # T better be > 10\n",
    "        # mode=='max': select state corresponding to max activation\n",
    "        # mode=='sample': select state based on softmax activation as probabilities\n",
    "        \n",
    "        if s_probe is None and ns_probe is None:\n",
    "            print(\"what do you want from meee??\")\n",
    "            return []\n",
    "        \n",
    "        # turn probes into keys\n",
    "        \n",
    "        s_index = self.find_state(self.states, s_probe) if s_probe is not None else -1\n",
    "        s_in = self.index_to_onehot(s_index, self.state_size) if s_index != -1 else None\n",
    "        ns_index = self.find_state(self.next_states, ns_probe) if ns_probe is not None else -1\n",
    "        ns_in = self.index_to_onehot(ns_index, self.state_size) if ns_index != -1 else None\n",
    "        \n",
    "        print('s_in: ', s_in)\n",
    "        print('ns_in: ', ns_in)\n",
    "        \n",
    "        if plan_steps==0:\n",
    "            # just activate the linked memories, no multiple copies needed\n",
    "            n = self.attractor_network.clone()\n",
    "            \n",
    "            for t in range(T):\n",
    "                sact, nsact, hact = n.forward(s_in=s_in, ns_in=ns_in)\n",
    "            \n",
    "            if ns_probe is None:\n",
    "                plan_indexes = self.activation_to_indexes(nsact, mode=mode)\n",
    "                plan_keys = [self.index_to_onehot(ind, self.state_size) for ind in plan_indexes]\n",
    "                plan = [self.retrieve_instance(self.next_states, key) for key in plan_keys]\n",
    "            else: # hopefully s_probe is None:\n",
    "                plan_indexes = self.activation_to_indexes(sact, mode=mode)\n",
    "                plan_keys = [self.index_to_onehot(ind, self.state_size) for ind in plan_indexes]\n",
    "                plan = [self.retrieve_instance(self.states, key) for key in plan_keys]\n",
    "            return plan\n",
    "\n",
    "        # make copies of the attractor network\n",
    "        sub_networks = [self.attractor_network.clone() for _ in range(plan_steps+1)]\n",
    "        \n",
    "        activation_buffer = {'sact': np.zeros((len(sub_networks), self.state_size)),\n",
    "                             'nsact':np.zeros((len(sub_networks), self.state_size)),\n",
    "                             'hact':np.zeros((len(sub_networks), self.hidden_size))}\n",
    "        \n",
    "        # insert probes\n",
    "        print('injecting s_in and ns_in...')\n",
    "        for t in range(1):\n",
    "            print('\\t s_in=', s_in, '\\n\\t ns_in=', ns_in)\n",
    "            sact, nsact, hact = sub_networks[0].forward(s_in=s_in)\n",
    "            activation_buffer['sact'][0] = sact\n",
    "            activation_buffer['nsact'][0] = nsact\n",
    "            activation_buffer['hact'][0] = hact\n",
    "            sact, nsact, hact = sub_networks[-1].forward(ns_in=ns_in)\n",
    "            activation_buffer['sact'][-1] = sact\n",
    "            activation_buffer['nsact'][-1] = nsact\n",
    "            activation_buffer['hact'][-1] = hact\n",
    "        \n",
    "        print(['%.2f' % x for x in activation_buffer['sact'][0]])\n",
    "        print(['%.2f' % x for x in activation_buffer['hact'][0]])\n",
    "        print(['%.2f' % x for x in activation_buffer['nsact'][0]])\n",
    "        \n",
    "        print('run recurrent computation...')\n",
    "        \n",
    "        # run recurrent computation and settle (?) on plan\n",
    "        # TODO: check convergence?\n",
    "        # keep injecting s_in and ns_in at both ends\n",
    "        for t in range(T):\n",
    "            \n",
    "            # propogate from state to goal\n",
    "            for i in range(len(sub_networks)):\n",
    "                if i==0:\n",
    "                    s = s_in\n",
    "                    ns = None # activation_buffer['sact'][i+1]\n",
    "                elif i==len(sub_networks)-1:\n",
    "                    s = None # activation_buffer['nsact'][i-1]\n",
    "                    ns = ns_in\n",
    "                else:\n",
    "                    s = activation_buffer['nsact'][i-1] # next state from last sub network\n",
    "                    ns = activation_buffer['sact'][i+1] # state from next sub network\n",
    "                \n",
    "                sact, nsact, hact = sub_networks[i].forward(s_in=s, ns_in=ns)\n",
    "                activation_buffer['sact'][i] = sact\n",
    "                activation_buffer['nsact'][i] = nsact\n",
    "                activation_buffer['hact'][i] = hact\n",
    "            \n",
    "            # propogate from goal back to state\n",
    "            for i in reversed(range(len(sub_networks))):\n",
    "                if i==len(sub_networks)-1:\n",
    "                    s = None # activation_buffer['nsact'][i-1]\n",
    "                    ns = ns_in\n",
    "                elif i==0:\n",
    "                    s = s_in\n",
    "                    ns = None # activation_buffer['sact'][i+1]\n",
    "                else:\n",
    "                    s = activation_buffer['nsact'][i-1] # next state from last sub network\n",
    "                    ns = activation_buffer['sact'][i+1] # state from next sub network\n",
    "                    \n",
    "                sact, nsact, hact = sub_networks[i].forward(s_in=s, ns_in=ns)\n",
    "                activation_buffer['sact'][i] = sact\n",
    "                activation_buffer['nsact'][i] = nsact\n",
    "                activation_buffer['hact'][i] = hact\n",
    "            \n",
    "            print(['%.2f' % x for x in activation_buffer['sact'][0]])\n",
    "            print(['%.2f' % x for x in activation_buffer['hact'][0]])\n",
    "            print(['%.2f' % x for x in activation_buffer['nsact'][0]])\n",
    "            print()\n",
    "        \n",
    "        # form plan\n",
    "        plan_indexes = self.activation_to_indexes(activation_buffer['nsact'][:-1], mode=mode)\n",
    "        print(plan_indexes)\n",
    "        plan_keys = [self.index_to_onehot(ind, self.state_size) for ind in plan_indexes]\n",
    "        # retrieve content from memory\n",
    "        plan = [self.retrieve_instance(self.next_states, key) for key in plan_keys]\n",
    "\n",
    "        return plan\n",
    "    \n",
    "    def activation_to_indexes(self, activation, mode='max'):\n",
    "        # activations is shape [B, state_size]\n",
    "        print(activation)\n",
    "        if mode=='max':\n",
    "            plan_indexes = np.argmax(activation, axis=-1)\n",
    "        elif mode=='sample':\n",
    "            plan_indexes = list(map(self.sample_state, activation))\n",
    "        return plan_indexes\n",
    "    \n",
    "    def sample_state(self, probs):\n",
    "        print(probs)\n",
    "        # in case there is a tie\n",
    "        elements = list(range(self.state_size))\n",
    "        return np.random.choice(elements, 1, p=probs)[0]\n",
    "\n",
    "    def find_link(self, links, link):\n",
    "        # finds first instance of same link in links else -1\n",
    "        for i, x in enumerate(links):\n",
    "            checks = [np.array_equal(getattr(x, f), getattr(link, f)) for f in x._fields]\n",
    "            if sum(checks) == len(checks):\n",
    "                return i\n",
    "        return -1\n",
    "\n",
    "    def find_state(self, states, state):\n",
    "        # finds first instance of state in states else -1\n",
    "        checks = [np.array_equal(x, state) for x in states]\n",
    "        if sum(checks)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return checks.index(True)\n",
    "\n",
    "    def retrieve_instance(self, memory, onehot_key):\n",
    "        # works for both link and state storages\n",
    "        if len(np.unique(onehot_key))!=2 or (sum(onehot_key) > 1):\n",
    "            # okay this isn't the perfect check but...\n",
    "            raise ValueError('invalid memory key!')\n",
    "        return memory[self.onehot_to_index(onehot_key)]\n",
    "\n",
    "    def onehot_to_index(self, onehot):\n",
    "        return np.where(onehot==1)[0][0]\n",
    "\n",
    "    def index_to_onehot(self, i, length):\n",
    "        key = np.zeros(length)\n",
    "        key[i] = 1.\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_ns(s):\n",
    "    x = []\n",
    "    for l in rmm.links:\n",
    "        if np.array_equal(s, l.state1):\n",
    "            x.append(rmm.find_state(rmm.next_states, l.state2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_ns(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmm = RemergeMemory(hidden_size=6, state_size=6)\n",
    "for x in memory.memory:\n",
    "    rmm.add(x.state, x.action, x.reward, x.next_state, x.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(rmm.links))\n",
    "print(len(rmm.states))\n",
    "print(len(rmm.next_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link 0:  0 --> 0\n",
      "link 1:  1 --> 1\n",
      "link 2:  0 --> 1\n",
      "link 3:  0 --> 2\n",
      "link 4:  2 --> 3\n",
      "link 5:  3 --> 0\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(rmm.links):\n",
    "    print('link %d'%i, end=':  ')\n",
    "    s = l.state1\n",
    "    ns = l.state2\n",
    "    print(rmm.find_state(rmm.states, s), '-->', rmm.find_state(rmm.next_states, ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rmm.links[0].state1\n",
    "ns = rmm.links[4].state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_in:  [1. 0. 0. 0. 0. 0.]\n",
      "ns_in:  [0. 0. 0. 1. 0. 0.]\n",
      "injecting s_in and ns_in...\n",
      "\t s_in= [1. 0. 0. 0. 0. 0.] \n",
      "\t ns_in= [0. 0. 0. 1. 0. 0.]\n",
      "['0.79', '0.05', '0.05', '0.05', '0.02', '0.02']\n",
      "['0.47', '0.00', '0.47', '0.05', '0.00', '0.00']\n",
      "['0.31', '0.31', '0.13', '0.13', '0.06', '0.06']\n",
      "run recurrent computation...\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.48', '0.48', '0.01', '0.01', '0.01', '0.01']\n",
      "\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.49', '0.49', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.49', '0.49', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.49', '0.49', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.49', '0.49', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "['1.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "['0.50', '0.00', '0.50', '0.00', '0.00', '0.00']\n",
      "['0.49', '0.49', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "[[0.49334484 0.49334484 0.00332832 0.00332778 0.00332711 0.00332711]]\n",
      "[0.49334484 0.49334484 0.00332832 0.00332778 0.00332711 0.00332711]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "plan = rmm.plan(s_probe=s, ns_probe=ns, plan_steps=1, T=6, mode='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19, 19)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6756a1e490>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC3CAYAAAALgwWHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJc0lEQVR4nO3dQYgW9x3G8efpSi67ObhYRZPQBpVCCHQpiwiBYigm2xIwObTEk4fQzaEeKr1IL8nRi2x7CAHTLuslJr1IPEhM8OKlghuQ1JSWLGKb7YqbYA/VS3Dz68Gx3ay772vemXf+84vfD8j7vvO+O/NzfHyYHWdWR4QAAPl8p/QAAIDBUOAAkBQFDgBJUeAAkBQFDgBJUeAAkNSmOl9se0rS7yWNSPpDRBzr9fmRsdHYND5eZ5PAhu7cvKmVW7fdxLrINrpko2wPXOC2RyS9IWm/pEVJl2yfiYi/bvQ1m8bHteM3vx50k0BPS8d/18h6yDa6ZqNs1zmFskfSQkRcjYgvJb0j6UCN9QFdQbaRQp0Cf0zSZ6teL1bLgOzINlKoU+DrnWu8775829O2523Pr9y6XWNzQGvINlKoU+CLkp5Y9fpxSUtrPxQRJyJiMiImR8ZGa2wOaA3ZRgp1CvySpN22n7T9iKSXJZ1pZiygKLKNFAa+CiUi7tg+LOmc7l5qNRsRn9QZZteRi3W+PL2Fmb0933/Y94/Ufx81gWw3j2z3N0i2a10HHhFnJZ2tsw6gi8g2MuBOTABIigIHgKQocABIigIHgKQocABIigIHgKQocABIigIHgKQocABIigIHgKQocABIigIHgKQocABIigIHgKRq/ThZNIufiYxvK7I9HByBA0BSFDgAJEWBA0BSFDgAJEWBA0BSFDgAJEWBA0BSXAfeIQsze3u+z7W0yIpsDwdH4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAEnVupHH9jVJ/5G0IulOREw2MRRQGtlGBk3ciflsRHzRwHqAriHb6DROoQBAUnULPCR9YPsj29NNDAR0BNlG59U9hfJMRCzZ3irpQ9t/i4gLqz9QhX9akkY2b665OaA1ZBudV+sIPCKWqsdlSacl7VnnMyciYjIiJkfGRutsDmgN2UYGAxe47VHbj957Luk5SVeaGgwohWwjizqnULZJOm373nrejoj3G5kKKItsI4WBCzwirkr6YYOzAJ1AtpEFlxECQFIUOAAkRYEDQFIUOAAkRYEDQFIUOAAkRYEDQFIUOAAkRYEDQFIUOAAkRYEDQFIUOAAkRYEDQFIUOAAk1cT/St+ac0uXe77//I6JliYB2kX2sR6OwAEgKQocAJKiwAEgKQocAJKiwAEgKQocAJKiwAEgqU5dB74ws7fn+zvf7f3+Ll2stf6ua2P+XUe+3fuwlLr77fkdw11/aWR7MByBA0BSFDgAJEWBA0BSFDgAJEWBA0BSFDgAJEWBA0BSFDgAJNX3Rh7bs5JekLQcEU9Xy8YlvSvp+5KuSfpFRPy77jD9LrTv+vrr6ncjQRfmLz1DkzdbkO32kO3+Bsn2gxyBz0maWrPsqKTzEbFb0vnqNZDNnMg2Eutb4BFxQdLNNYsPSDpZPT8p6cWG5wKGjmwju0HPgW+LiOuSVD1ubW4koCiyjTSG/o+Ytqdtz9ueX7l1e9ibA1pDtlHaoAV+w/Z2Saoelzf6YESciIjJiJgcGRsdcHNAa8g20hi0wM9IOlQ9PyTpvWbGAYoj20ijb4HbPiXpz5J+YHvR9iuSjknab/tTSfur10AqZBvZ9b0OPCIObvDWTxqeBWgV2UZ23IkJAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAElR4ACQFAUOAEltKj0A/m/XkYulRwCGgmwPB0fgAJAUBQ4ASVHgAJAUBQ4ASVHgAJAUBQ4ASVHgAJBU3+vAbc9KekHSckQ8XS17XdIvJX1efey3EXF2WEM+LBZm9vZ8n2tpm0W220O2h+NBjsDnJE2ts3wmIiaqXwQcGc2JbCOxvgUeERck3WxhFqBVZBvZ1TkHftj2x7ZnbW9ubCKgPLKNFAYt8Dcl7ZQ0Iem6pOMbfdD2tO152/Mrt24PuDmgNWQbaQxU4BFxIyJWIuIrSW9J2tPjsyciYjIiJkfGRgedE2gF2UYmAxW47e2rXr4k6Uoz4wBlkW1k8iCXEZ6StE/SFtuLkl6TtM/2hKSQdE3Sq0OcERgKso3s+hZ4RBxcZ/EfhzAL0Cqyjey4ExMAkqLAASApChwAkqLAASApChwAkqLAASApChwAkqLAASApChwAkqLAASApChwAkqLAASApChwAkqLAASApChwAkur788DbtDCzt/QIncb+yYs/u97YP4PhCBwAkqLAASApChwAkqLAASApChwAkqLAASApChwAknJEtLcx+3NJ/1i1aIukL1ob4Jtjvnranu97EfHdFrf3P2S7ccz3detmu9UCv2/j9nxETBYboA/mq6fr8w1T13/vzFdPV+bjFAoAJEWBA0BSpQv8ROHt98N89XR9vmHq+u+d+erpxHxFz4EDAAZX+ggcADCgIgVue8r2320v2D5aYoZ+bF+z/Rfbl23Pd2CeWdvLtq+sWjZu+0Pbn1aPmzs23+u2/1Xtw8u2f1ZqvrZ0PdvkupH5OpPr1gvc9oikNyT9VNJTkg7afqrtOR7QsxEx0YXLhSTNSZpas+yopPMRsVvS+ep1KXO6fz5Jmqn24UREnG15plYlyja5fnBz6nCuSxyB75G0EBFXI+JLSe9IOlBgjlQi4oKkm2sWH5B0snp+UtKLrQ61ygbzPWzI9jdEruspUeCPSfps1evFalnXhKQPbH9ke7r0MBvYFhHXJal63Fp4nvUctv1x9a1osW+FW5Ih2+S6GZ3IdYkC9zrLungpzDMR8SPd/Xb4V7Z/XHqghN6UtFPShKTrko6XHWfoMmSbXNfXmVyXKPBFSU+sev24pKUCc/QUEUvV47Kk07r77XHX3LC9XZKqx+XC83xNRNyIiJWI+ErSW+rmPmxS57NNruvrUq5LFPglSbttP2n7EUkvSzpTYI4N2R61/ei955Kek3Sl91cVcUbSoer5IUnvFZzlPvf+ElZeUjf3YZM6nW1y3Ywu5br1/5U+Iu7YPizpnKQRSbMR8Unbc/SxTdJp29LdffR2RLxfciDbpyTtk7TF9qKk1yQdk/Qn269I+qekn3dsvn22J3T3NMI1Sa+Wmq8NCbJNrpuZrzO55k5MAEiKOzEBICkKHACSosABICkKHACSosABICkKHACSosABICkKHACS+i/JRKu9ASFw5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(s[0])\n",
    "axes[1].imshow(ns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f67568e1910>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(s[0])\n",
    "axes[1].imshow(plan[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
